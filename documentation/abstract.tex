%!TEX root=thesis.tex
%This is the draft abstract. More soon, I promise!
Text classification is one of main task in natural language processing (NLP). Text classification assigns text into pre-defined categories. The document representation method used to extract features from text usually resulted in large and sparse matrix. The high dimensionality of the matrix would be a hindrance to the accuracy of the classification models. Thus, dimension reduction algorithm is applied to reduce the dimension of these large and sparse matrix. This study analyse effect of dimension reduction on the matrix from different document representation algorithm and subsequently the performance of the classification models trained from the original large and sparse matrix and the resulting matrix from different dimension reduction algorithms. The performance of the classification models are evaluated to identify the optimized dimension representation algorithm, dimension reduction algorithm and classification model.\\

\textbf{Keywords: } Natural Language Processing (NLP), text classification, dimension reduction, classification models, accuracy, term frequency, term frequency-inverse document frequency (TF-IDF), k-Nearest Neighbor (kNN), Support Vector Machine (SVM), Neural Network (NN), truncated Single Value Decomposition (SVD).
