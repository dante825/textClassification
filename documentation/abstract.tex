%!TEX root=thesis.tex
%This is the draft abstract. More soon, I promise!
Text classification is one of the main tasks in \ac{nlp}. Text classification assigns text into pre-defined categories. The common document representation method used to extract features from text usually produce a large and sparse matrix. The high dimensionality of the matrix would be a hindrance to the accuracy of the classification models. Thus, dimension reduction algorithm is applied to reduce the dimension of these large and sparse matrix. This study analyse effect of dimension reduction on the matrix from different document representation algorithm and subsequently the performance of the classification models trained from the original large and sparse matrix and the resulting matrix from different dimension reduction algorithms. The performance of the classification models in these different scenarios are evaluated, in order to identify the optimized dimension representation algorithm, dimension reduction algorithm and classification model.\\

\textbf{Keywords: } Natural Language Processing (\ac{nlp}), text classification, dimension reduction, classification models, accuracy, term frequency, \ac{tfidf}, \ac{knn}, \ac{svm}, \ac{nn}, truncated \ac{svd}.
