%!TEX ROOT = main.tex
\chapter{Introduction}
\section{Introduction}
In this digital age, data is being generated rapidly and in large quantity. Much of the data generated is unstructured data which includes text messages, scientific articles, news articles, blog posts and others. \cite{bigData}. News articles is one of the main sources of these data. News articles are generated around the world at all times. News articles are generated in large quantity and in high velocity that is beyond one's capability to analyse each of them in time. Thankfully, as the news articles generation capacity increases so do the capability of \ac{ai}. A branch of \ac{ai} is created specifically to automate the process with text and speech. The branch of \ac{ai} is Natural Language Processing (\ac{nlp}).

The objective of \ac{nlp} is to allow computer to understand human natural languages. If the objective is achieved, \ac{nlp} would be able to read and understand all form of human natural languages including text  and speech as well as any human, if not better. In the meantime, although the capability of \ac{nlp} has not reach the ideal yet, it has improved over the years. \Ac{nlp} would be able to analyse the sentiment of text, sentiment analysis; recognized named entity, named entity recognition; classify text into different groups, text classification among others.

Text classification is the main topic in this research. It is one of the NLP method that group text into different topics or categories. This classification would be helpful for users to narrow down a search quickly, or to know the main topic of the text in a short time. This is especially the case with news articles, it would be great if the news articles are being categorized into distinctive categories according to the user's preferences. Categorized news would be much easier to search through.

The technology breakthrough in recent years, machine learning algorithms, processing power of processors have been a boost to the \ac{nlp} field. With the breakthroughs, there has been a rapid development of new techniques in \ac{nlp} and \ac{ai} that can work without domain experts' supervision. These breakthrough has brought new attempts at text classification at news articles as well. Researchers have try to apply these breakthroughs on text classification on Indonesian news articles. For instance, researchers in Indonesia has created models to classify Indonesian news. \cite{WONGSO2017137}. Indonesian news is still based on Latin characters in which the hurdles are less intimidating. There are researches that create classification models on Arabic news articles. \cite{arabicNews}. Arabic characters have distinctive differences with Latin characters and new and novel methods have to be applied.

There are several approaches to the text classification problem, multi-label where each document can belong to several categories or classification, where each document can only belong to one category. Besides classification and multi-labeling, there is clustering, which is an unsupervised machine learning method. In clustering, the data is not labeled and is grouped by similarities based on a similarity measure. This research shall focus on classification rather than multi-label and clustering.

In text classification, most of the algorithms used vector space model to represent the unstructured textual data. \cite{vectorSpaceModelText}. This vector space model represent the sequence of the textual features and their weight, it is easy to implement and provide uniform representation for documents. However, it has a drawback, since it represent all the words in the documents, the dimension of the vector would be huge. This huge vector space model would impact the performance of the machine learning tasks. \cite{knnVectorSpaceReduction}. Therefore, this study would investigate the effect of dimension reduction on vector space model and subsequently the performance of classification models in text classification.\\


\subsection{Problem Statement}
Vector space model is one of the most commonly used document representation algorithms in most of the fields, news article text classification included. However, dimension of the feature space from vector space model can be too large and the vectors can be too sparse. This large and sparse vector space would present difficulties to the classification models. Dimension reduction could reduce the dimension of the vector space model so that the vector space is not that large and sparse but this reduction would certainly affect the performance of the classification models. Different document representation method would produce different vector space model on the same news article. Different dimension reduction method applied on the same vector space model also produces different outcomes. With the same reduced vector space model, different classification models would produced varied result. This research would attempt to provide an insight into which combination of the document representation, dimension reduction and classification models would produce a satisfactory result.\\

\subsection{Research Objectives}
\begin{enumerate}
	\item To identify a document representation algorithm that can extract features from news articles in optimum condition.
	\item To investigate the effect of dimension reduction on feature matrix has on the performance of text classification models.
	\item To evaluate the performance of the chosen text classification models with different document representation method and dimension reduction method.
\end{enumerate}


\subsection{Research Questions}
\begin{enumerate}
	\item Which document representation method is optimized to extract the features from news articles?
	\item How would dimension reduction influence the accuracy and performance of text classification models?
	\item Which of the combination of document representation method, dimension reduction method and text classification model has the better performance?
\end{enumerate}

\subsection{Research Motivation}
In this age of consumerism, people are eager to consume everything, news is one of the consumption product. Events are happening everywhere in this world and news articles are the vehicle that make the events public knowledge. There are numerous news agency around the world and they are churning out news around the clock. The amount of news generated is more than what a single human can consume and analysed. This is where \ac{nlp} would be able to help. This study is about text classification, one of the pillars of \ac{nlp}.

In text classification, the unstructured text or news articles in this case would be given a label or multiple labels depend on the method used. These labels would make the news articles more meaningful and searchable. Users can search for a topic just by selecting the text with the particular label rather than performing a manual key word search on all the news articles. In another scenario, users could know what is the topic of a news article in real time if they feed the news article to a text classification model.

\ac{bow} is the most commonly used document representation method in text classification. \Ac{bow} would produce a vector space model of the textual data representation. The dimension of this vector space model would be huge because the amount of words in the documents is large. This huge dimension of vector space model would be a problem to text classification models as the models need a large amount of memory to store this huge and sparse matrix. Furthermore, in order for the classification models to learn from the patterns of the large matrix and able to classify another text correctly, this would need an immense amount of computing power to process the huge and sparse matrix.

With the emergence of dimension reduction algorithms, the dimension of the vector space could be decreased, less memory would be needed to store the matrix and less computing power would be needed to process the matrix. Compressing or transforming the huge matrix into a matrix with lesser dimension would need some computing power as well. This is the cost to reduce the dimension. This reduction of dimension in the vector space model would certainly affect the performance of the text classification models. This study would find out what are those effects.

This study would investigate the effect of dimension reduction algorithms on different document representation method and subsequently the performance of text classification models.\\

\subsection{Research Significance}
This study would classify news articles into different categories. In order to do that, first the features have to be extracted from the text of the news articles, document representation. The features might need to be compressed or transformed, dimension reduction. Then the transformed features are used to train classification models. After that, the trained models are validated and tested to evaluate its performance.

There are a number of document representation methods, each of these methods would have its advantages and disadvantages over one another. In addition to dimension reduction and classification algorithms, there are myriad of combinations of these algorithms from the 3 stages in order to produce a satisfactory classification models. 

This study would explore some of these methods in each of the stages namely document representation, dimension reduction and classification models. This study is trying to determine which combination of document representation method, dimension reduction and classification model would have the best performance. The way to get to the bottom of these question is to apply the chosen methods to a dataset and analyse the result.

Text classification on news articles would work fine if not better without dimension reduction, but dimension reduction still has its uses. In the situation where memory is a constraint, dimension reduction could reduce the amount of memory needed to store the feature matrix. Even with this reduction in memory space, the accuracy must be proven to be still at a satisfactory level. This study would attempt to find a combination of method that could find the said sweet spot where memory space needed is lesser and yet a comparable accuracy is achieved. If this is found and proven, text classification would be more widespread. Smaller devices with less memory would be able to perform text classification on the fly.\\


\subsection{Expected Outcome}
\begin{enumerate}
	\item A prototype text classification model that can achieve a satisfactory accuracy in optimum condition
	\item A working pipeline of converting raw text to vector space model or features to be processed by classification models
	\item A suitable text classification algorithm is applied on the text classification application
	\item A performance evaluation on the text classification models when dimension reduction algorithms are applied
\end{enumerate}

