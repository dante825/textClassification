%!TEX ROOT = main.tex
\chapter{Introduction}
\section{Introduction}
In this digital age, data is being generated rapidly and in large quantity. Much of the data generated is unstructured data which includes text messages, scientific articles, news articles, blog posts and others. \cite{bigData}. The data is generated in large quantity and in high velocity that is beyond human's capability to analyse each of them in time. Thankfully, as the data generation capacity increases so do the capability of \ac{ai}. A branch of \ac{ai} is created specifically to automate the process with text and speech. The branch of \ac{ai} is Natural Language Processing (\ac{nlp}).

The objective of \ac{nlp} is to allow computer to understand human natural languages. If the objective is achieved, \ac{nlp} would be able to read and understand all form of human natural languages including text  and speech as well as any human, if not better. In the meantime, although the capability of \ac{nlp} has not reach the ideal yet, it has improved over the years. \Ac{nlp} would be able to analyse the sentiment of text, sentiment analysis; recognized named entity, named entity recognition; classify text into different groups, text classification among others.

Text classification is the main topic in this research. It is one of the NLP method that group text into different topics or categories. This classification would be helpful for users to narrow down a search quickly, or to know the main topic of the text in a short time.

The technology breakthrough in recent years, machine learning algorithms, processing power of processors have been a boost to the \ac{nlp} field. With the breakthroughs, there has been a rapid development of new techniques in \ac{nlp} and \ac{ai} that can work without domain experts' supervision.

There are several approaches to the text classification problem, multi-label where each document can belong to several categories or classification, where each document can only belong to one category. Besides classification and multi-labeling, there is clustering, which is an unsupervised machine learning method. In clustering, the data is not labeled and is grouped by similarities based on a similarity measure. This research shall focus on classification rather than multi-label and clustering.

In text classification, most of the algorithms used vector space model to represent the unstructured textual data. \cite{vectorSpaceModelText}. This vector space model represent the sequence of the textual features and their weight, it is easy to implement and provide uniform representation for documents. However, it has a drawback, since it represent all the words in the documents, the dimension of the vector would be huge. This huge vector space model would impact the performance of the machine learning tasks. \cite{knnVectorSpaceReduction}. Therefore, this study would explore the effect of dimension reduction on vector space model has on text classification.\\

\subsection{Problem Statement}
Vector space model is one of the most commonly used document representation algorithms in most of the fields, news article text classification included. However, dimension of the feature space from vector space model can be too large and the vectors can be too sparse. This large and sparse vector space would present difficulties to the classification models. Dimension reduction could reduce the dimension of the vector space model so that the vector space is not that large and sparse but this reduction would certainly affect the performance of the classification models. Different document representation method would produce different vector space model on the same news article. Different dimension reduction method applied on the same vector space model also produces different outcomes. With the same reduced vector space model, different classification models would produced varied result. This research would attempt to provide an insight into which combination of the document representation, dimension reduction and classification models would produce a satisfactory result.\\

\subsection{Research Objectives}
\begin{enumerate}
	\item To identify a document representation algorithm that can extract features from news articles in optimum condition.
	\item To investigate the effect of dimension reduction on feature matrix has on the performance of text classification models.
	\item To evaluate the performance of the 3 chosen text classification models with different document representation method and dimension reduction method.
\end{enumerate}


\subsection{Research Questions}
\begin{enumerate}
	\item Which document representation method is optimized to extract the features from news articles?
	\item How would dimension reduction influence the accuracy and performance of text classification models?
	\item Which of the combination of document representation method, dimension reduction method and text classification model has the better performance?
\end{enumerate}

\subsection{Research Motivation}
In the age of big data, the amount of data generated and collected is growing at an explosive rate. Much of the data generated and collected is in the form of unstructured text. The value contained within the text need to be extracted so that it can be useful to the users. Natural Language Processing (\ac{nlp}) would be able to do so. Text classification is one of the pillars of \ac{nlp}.

In text classification, the unstructured text would be given a label or multiple labels depend on the method used. These labels would make the data more meaningful and searchable. Users can search for a topic just by selecting the text with the particular label rather than performing a manual key word search on all the text document. In another scenario, users could know what is the topic of a text in real time if they feed the text to a text classification model.

\ac{bow} is the most commonly used document representation method in text classification. \Ac{bow} would produce a vector space model of the textual data representation. The dimension of this vector space model would be huge because the amount of words in the documents is large. This huge dimension of vector space model would be a problem to text classification models as the models need a large amount of memory to store this huge and sparse matrix. Furthermore, in order for the classification models to learn from the patterns of the large matrix and able to classify another text correctly, this would need an immense amount of computing power to process the huge and sparse matrix.

With the emergence of dimension reduction algorithms, the dimension of the vector space could be decreased, less memory would be needed to store the matrix and less computing power would be needed to process the matrix. Compressing or transforming the huge matrix into a matrix with lesser dimension would need some computing power as well. This is the cost to reduce the dimension. Would this cost incurred increase the performance of the text classification models? Or the performance of the classification models would deteriorate?

This study would investigate the effect of dimension reduction algorithms on different document representation method and subsequently the performance of text classification models.\\

\subsection{Research Significance}
This research would classify news articles into different categories. In order to do that, first the features have to be extracted from the text. The features might need to be compressed or transformed. Then the transformed features are used to train classification models. After that, the trained models are validated and tested to evaluate its performance.

Bag of words (\ac{bow}) approach is the most commonly used document representation method. In this approach, the documents are converted into vector space models. Due to the large amount of words in the documents, the vector space would be large and sparse. This large and sparse matrix would negatively impact the performance of classification models which is known as the curse of dimensionality.

By applying dimension reduction algorithms to the vector space model, the vector space and sparsity of the vector would be reduced. With this reduced vector, the classification models would need to process less information. The performance of the classification models would certainly be influenced by this reduction in dimension. Different dimension reduction algorithms also would result in different reduced vector space. The initial matrix from different bag of words or term vector approach also would produce vector space models with distinct differences.

This study is trying to answer these few questions on which combination of document representation method, dimension reduction and classification model would have the best performance. The way to get to the bottom of these is to apply the few methods to a dataset and analyse the result.\\


\subsection{Expected Outcome}
\begin{enumerate}
	\item A prototype text classification model that can achieve a satisfactory accuracy in optimum condition
	\item A working pipeline of converting raw text to vector space model or features to be processed by classification models
	\item A suitable text classification algorithm is applied on the text classification application
	\item A performance evaluation on the text classification models when dimension reduction algorithms are applied
\end{enumerate}

