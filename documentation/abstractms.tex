%!TEX root=thesis.tex
%This is the draft abstract. More soon, I promise!
Klasifikasi teks adalah salah satu tugas utama dalam \ac{nlp}. Klasifikasi teks memberikan teks ke dalam kategori yang telah ditentukan sebelumnya. Pengelasan teks diperlukan dalam artikel berita untuk membezakan artikel ke dalam beberapa kategori untuk memudahkan pencarian. Artikel berita dalam kategori yang berbeze menpunyai ciri yang agak serupa, ini adalah satu cabaran untuk kaedah klasifikasi teks. Kaedah perwakilan dokumen biasa yang digunakan untuk mengekstrak ciri-ciri dari teks biasanya menghasilkan matriks yang besar dan jarang. Keamatan dimensi matriks akan menjadi penghalang kepada ketepatan model klasifikasi. Oleh itu, algoritma pengurangan dimensi digunakan untuk mengurangkan dimensi matriks besar dan jarang ini. Kajian ini menganalisis kesan pengurangan dimensi kepada algoritma perwakilan dokumen yang berlainan dan seterusnya prestasi model klasifikasi. Pendapatan kajian ini mendapati bahawa \ac{svm} mempunyai prestasi keseluruhan yang terbaik berbanding dengan \ac{knn} dan \ac{nn}. Berdasarkan hasil kajian ini, \ac{tfidf} adalah kaedah perwakilan dokumen yang lebih baik berbanding dengan kekerapan terma. Prestasi model klasifikasi menurun apabila pengurangan dimensi diterapkan sejak bilangan ciri yang tersedia kurang. Pengurangan dimensi adalah proses perhitungan mahal, ia memerlukan masa yang lebih panjang. Hasil terbaik dicapai tanpa pengurangan dimensi tetapi pengurangan dimensi masih dapat memenuhi tujuannya apabila terdapat kendala memori untuk menyimpan ciri-ciri tersebut.