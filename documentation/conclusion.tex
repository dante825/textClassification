%!TEX ROOT = main.tex
\chapter{Conclusion}
It is known that \ac{tfidf} should be better than term frequency but Moldagulova, Aiman and Sulaiman, Rosnafisah proposed that with term frequency and naive dimension reduction, \ac{knn} classification model would be able to achieve a satisfactory result. \cite{knnVectorSpaceReduction}. Therefore, this research compare term frequency and \ac{tfidf} and apply different dimension reduction methods to both. The implementation of the \ac{knn} algorithm in this research might differ from that proposed by the authors. They divided the larger feature matrix into parts and train by part.

From the results of the experiments it is shown that \ac{tfidf} is a better document representation method than term frequency. Classification models can achieved a better result with \ac{tfidf} than term frequency. With term frequency as the document representation method, \ac{svm} and \ac{nn} are able to achieve satisfactory accuracy but the accuracy achieved with \ac{tfidf} is slightly higher. The advantage of \ac{tfidf} is more obvious, with \ac{knn}, with term frequency the accuracy is a meagre 0.31 but with \ac{tfidf}, the accuracy is 0.76 which is close to 0.80.

By applying the 2 types of dimension reduction to both the document representation method, the effect of dimension reduction on the performance of the classification models is analysed. The classification models accuracy from both naive dimension reduction and truncated \ac{svd} are quite similar in most cases. However, truncated \ac{svd} has a slight edge over naive dimension reduction. Truncated \ac{svd} can provide classification models with more prominent features and subsequently higher accuracy.

As the dimension of the vector space model is reduced, the accuracy of the classification models would decreased due to the lack of features or information. This reduction of features would reduce the memory used to store the vector space model. However, the reduction process would need intensive computing power and time, especially in the case of truncated \ac{svd}. This the trade off between dimension reduction and classification accuracy. The gain in less memory to store the matrix would cause an increase in computing power consumed and time taken.

Out of the 3 classification models tested in this research, \ac{svm} has the best overall performance. \Ac{svm} can achieve a satisfactory accuracy in most scenarios and the time taken for \ac{svm} to predict the test data is among the shortest. Thus \ac{svm} would be the best classification models in text classification.

For future works, ways to improve the accuracy of the classification models with \ac{tfidf} should be explored. More document representation method, such as n-gram could be apply alongside \ac{tfidf} and different dimension reduction could be applied. \Ac{tfidf} does not take the semantic of the term into account just the frequency and rarity, n-gram would be able to rectify part of the problem.\\
