%!TEX ROOT = main.tex
\chapter{Conclusion}
It is known that \ac{tfidf} should be better than term frequency but Moldagulova, Aiman and Sulaiman, Rosnafisah proposed that with term frequency and naive dimension reduction, \ac{knn} classification model would be able to achieve a satisfactory result. \cite{knnVectorSpaceReduction}. Therefore, this research compare term frequency and \ac{tfidf} and apply different dimension reduction methods to both. The implementation of the \ac{knn} algorithm in this study might differ from that proposed by the authors. They divided the larger feature matrix into parts and train the classification model by part.

From the results of the experiments it is shown that \ac{tfidf} is a better document representation method than term frequency. Classification models can achieved a better result with \ac{tfidf} than term frequency. With term frequency as the document representation method, \ac{svm} and \ac{nn} are able to achieve satisfactory accuracy but the accuracy achieved with \ac{tfidf} is slightly higher. The advantage of \ac{tfidf} is more obvious, with \ac{knn}, with term frequency the accuracy is a meager 0.31 but with \ac{tfidf}, the accuracy is 0.76 which is close to 0.80.

By applying the 2 types of dimension reduction to both the document representation method, the effect of dimension reduction on the performance of the classification models is analysed. The classification models accuracy from both naive dimension reduction and truncated \ac{svd} are quite similar in most cases. However, truncated \ac{svd} has a slight edge over naive dimension reduction. Truncated \ac{svd} can provide classification models with more prominent features and subsequently higher accuracy.

As the dimension of the vector space model is reduced, the accuracy of the classification models would decreased due to the lack of features or information. This reduction of features would reduce the memory used to store the vector space model. However, the reduction process would need intensive computing power and time, especially in the case of truncated \ac{svd}. This the trade off between dimension reduction and classification accuracy. The gain in less memory to store the matrix would incurred an increment in computing power consumption and time taken.

Out of the 3 classification models tested in this research, \ac{svm} has the best overall performance. \Ac{svm} can achieve a satisfactory accuracy in most scenarios and the time taken for \ac{svm} to predict the test data is among the shortest. Thus \ac{svm} would be the best classification models out of the 3 classification models studied in text classification.

For future works, more document representation method, such as n-gram or tree could be applied on the news article aside from \ac{tfidf}. \Ac{tfidf} does not take the semantic of the term into consideration, only its frequency and rarity which is its major drawback. \cite{tfidfDrawback}. N-gram and tree representation method would take the semantic of the word into consideration, this document representation might be able to extract more features and information from news articles, and subsequently increase the performance of the classification models.\\
